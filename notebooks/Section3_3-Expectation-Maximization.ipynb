{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width: 90%;\n",
       "/*        margin-left:auto;*/\n",
       "/*        margin-right:auto;*/\n",
       "    }\n",
       "    ul {\n",
       "        line-height: 145%;\n",
       "        font-size: 90%;\n",
       "    }\n",
       "    li {\n",
       "        margin-bottom: 1em;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top: 12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width: 90%;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectation maximization (EM) uses iterative optimization along with a latent variable model to obtain maximum likelihood estimates for models whose parameters are difficult to estimate directly. It may not be intuitive how introducing latent (missing) elements to a problem will facilitate its solution, but it works essentially by breaking the optimization into two steps:\n",
    "\n",
    "1. generating an **expectation** over the missing variable(s) based on current estimates of parameters\n",
    "2. **maximizing** the log-likelihood from the expectation step, thereby generating updated estimates of parameters\n",
    "\n",
    "EM is particularly suited to estimating the parameters of *mixture models*, where we do not know from which component each observation is derived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, suppose we have observed quantities $x = x_1,\\ldots,x_n$ and unobserved (latent) quantities $z$ that are derived from some joint model:\n",
    "\n",
    "$$(x,z) \\sim P(x,z|\\theta)$$\n",
    "\n",
    "We are interested in obtaining the MLE for the marginal distribution of $X$:\n",
    "\n",
    "$$x \\sim P(x|\\theta)$$\n",
    "\n",
    "However, it is difficult to marginalize over $Z$ and maximize. EM gets around this by iteratively improving an initial estimate $\\theta^{(0)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Mixture of normals\n",
    "\n",
    "Consider a set of observations, each of which has been drawn from one of two populations:\n",
    "\n",
    "$$x^{(a)} \\sim N(\\mu_a, \\sigma^2_a)$$\n",
    "$$x^{(b)} \\sim N(\\mu_b, \\sigma^2_b)$$\n",
    "\n",
    "except we only observe the values for $x = [x^{(a)}, x^{(b)}]$, not the labels which identify which population they are derived from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10892d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# True parameter values\n",
    "mu_true = [2, 5]\n",
    "sigma_true = [1, 2]\n",
    "psi_true = .4\n",
    "n = 100\n",
    "\n",
    "# Simulate from each distribution according to mixing proportion psi\n",
    "z = np.random.binomial(1, psi_true, n)\n",
    "x = [np.random.normal(mu_true[i], sigma_true[i]) for i in z]\n",
    "\n",
    "_ = plt.hist(x, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed data is then a finite mixture of normal distributions:\n",
    "\n",
    "$$X = (1 - \\psi)X^{(a)} + \\psi X^{(b)}$$\n",
    "\n",
    "This is a generative representation of the data, whereby unobserved labels $z_i$ are generated according to probability $\\psi$. We might try to maximize the log likelihood of the joint distribution above, via maximum likelihood:\n",
    "\n",
    "$$l(\\theta) = \\sum_i \\log\\left[(1 - \\psi)\\phi^{(a)}(x_i) + \\psi \\phi^{(b)}(x_i)\\right] $$\n",
    "\n",
    "$$\\text{where } \\theta = \\{\\psi, \\mu^{(a)}, \\sigma^{(a)}, \\mu^{(b)}, \\sigma^{(b)}\\}$$\n",
    "\n",
    "However, this function is very difficult to maximize, and turns out to be bimodal. A simpler approach is to consider the data labels to be unobserved data, and incorporate them into the model. This is generally called a *data augmentation* approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint distribution of $x$ and $z$ can be factorized into:\n",
    "\n",
    "$$P(x_i,z_i) = P(x_i \\,|\\, z_i)P(z_i)$$\n",
    "\n",
    "It is reasonable to model $z$ as:\n",
    "\n",
    "$$\\{z_i\\} \\sim \\text{Bernoulli}(\\psi)$$\n",
    "\n",
    "where $\\psi$ is the probability of membership in group \"b\" (hence, $1-\\psi$ is the probability of group \"a\" membership). Note that this generalizes to $k$ components in the mixture, where $z_i \\sim \\text{Multinomial}(\\psi)$ with $\\psi$ of dimension $k-1$.\n",
    "\n",
    "Clearly, the distribution of $x$ conditional on $z$ is:\n",
    "\n",
    "$$(x_i | z_i = j) \\sim N(\\mu_j, \\sigma_j)$$\n",
    "\n",
    "If we knew the $\\{z_i\\}$, then we could simply use MLE to obtain estimates for the paramters of the model. However, we do not know the labels, which makes this a form of *unsupervised learning*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "Continuing with the mixture of normals model as our example, we can apply the EM algorithm to estimate $\\theta = \\{\\mu, \\sigma, \\psi\\}$.\n",
    "\n",
    "**Initiazlize** $\\theta_0 = \\{\\mu_0, \\sigma_0, \\psi_0\\}$\n",
    "\n",
    "**Repeat until convergence:**\n",
    "\n",
    "- **E-step**: guess the values of $\\{z_i\\}$\n",
    "\n",
    "    Compute probabilities of group membership: $w_{ij} = P(z_i = j | x_i, \\theta)$ for each group $j=1,\\ldots,k$. This is done via Bayes' formula:\n",
    "    \n",
    "    $$P(z_i = j | x_i) = \\frac{P(x_i | z_i=j) P(z_i=j)}{\\sum_{l=1}^k P(x_i | z_i=l) P(z_i=l)}$$\n",
    "    \n",
    "    $\\theta$ has been dropped for notational convenience.\n",
    "    \n",
    "- **M-step**: update estimates of parameters $\\theta$\n",
    "\n",
    "    $$\\begin{aligned}\\psi_j &= \\frac{1}{m} \\sum_i w_{ij} \\\\\n",
    "      \\mu_j &= \\frac{\\sum_i w_{ij} x_i}{\\sum_i w_{ij}} \\\\\n",
    "      \\sigma_j &= \\frac{\\sum_i w_{ij}(x_i - \\mu_j)^2}{\\sum_i w_{ij}}\n",
    "    \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General formulation\n",
    "\n",
    "Recall **Jensen's inequality**:\n",
    "\n",
    "> Let $f$ be a convex function (*i.e.* $f^{\\prime\\prime} \\ge 0$) of a random variable X. Then:\n",
    "> $f(E[X]) \\le E[f(X)]$\n",
    "\n",
    "And when $f$ is *strictly* convex, then:\n",
    "\n",
    "$$E[f(X)] = f(E[X]) \\iff X = E[X]$$\n",
    "\n",
    "with probability 1.\n",
    "\n",
    "Consider again the joint density $P(x,z|\\theta)$, where only $x$ is observed. We want to be able to maximize:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "l(x \\,|\\, \\theta) &= \\sum_i \\log P(x_i \\,|\\, \\theta) \\\\\n",
    "&= \\sum_i \\log \\sum_{z_i} P(x_i, z_i \\,|\\, \\theta)\n",
    "\\end{aligned}$$\n",
    "\n",
    "however, evaluating this is difficult when the $\\{z_i\\}$ are unobserved.\n",
    "\n",
    "The EM algorithm iteratively calculates *lower bounds on the likelihood* for the current values of the parameters, then *maximizes the lower bound* to update the parameters.\n",
    "\n",
    "Since $z_i$ is a random variable, perhaps we can construct its density $Q_i$ and use it to marginalize the joint likelihood:\n",
    "\n",
    "$$\\sum_i \\log \\sum_{z_i} P(x_i, z_i \\,|\\, \\theta) = \\sum_i \\log \\sum_{z_i} Q_i(z_i) \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)}$$\n",
    "\n",
    "This turns the inner summation into an expectation.\n",
    "\n",
    "$$\\sum_i \\log \\sum_{z_i} Q_i(z_i) \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} = \\sum_i \\log E_{Q_i} \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right]$$\n",
    "\n",
    "Now, if we apply Jensen's inequality (note that the logarithm is a *concave* function, so the inequality is reversed):\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\sum_i \\log E_{Q_i} \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right] &\\ge \\sum_i  E_{Q_i} \\log \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right] \\\\\n",
    "&= \\sum_i \\sum_{z_i}  Q_i(z_i) \\log \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right]\n",
    "\\end{aligned}$$\n",
    "\n",
    "We need to ensure that the equality condition holds true, which we can do by choosing $Q_i$ appropriately. Specifically, we want a $Q_i$ such that:\n",
    "\n",
    "$$\\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} = C$$\n",
    "\n",
    "which implies:\n",
    "\n",
    "$$Q_i(z_i) \\propto P(x_i, z_i \\,|\\, \\theta)$$\n",
    "\n",
    "Since $Q_i$ is a density,\n",
    "\n",
    "$$\\begin{aligned}\n",
    "Q_i(z_i) &= \\frac{P(x_i, z_i \\,|\\, \\theta)}{\\sum_{z_i} P(x_i, z_i \\,|\\, \\theta)} \\\\\n",
    "&= \\frac{P(x_i, z_i \\,|\\, \\theta)}{P(x_i \\,|\\, \\theta)} \\\\\n",
    "&= P(z_i \\,|\\, x_i, \\theta)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to our normal mixture example:\n",
    "\n",
    "For the **E-step** we need to identify $Q_i(z_i)$\n",
    "\n",
    "$$Q_i(z_i) = P(z_i \\,|\\, x_i, \\mu, \\sigma, \\psi)$$\n",
    "\n",
    "Via Bayes' formula:\n",
    "\n",
    "$$P(z_i=j \\,|\\, x_i) = \\frac{P(x_i \\,|\\, z_i=j)P(z_i=j)}{\\sum_l P(x_i \\,|\\, z_i=l)P(z_i=l)}$$\n",
    "\n",
    "where $P(x_i \\,|\\, z_i=l)$ is just the $j$th Normal distribution of the mixture, and $P(z_i=l)$ is a multinomial probability.\n",
    "\n",
    "This gives us:\n",
    "\n",
    "$$P(z_i=1 \\,|\\, x_i) = \\frac{\\psi N(\\mu_b, \\sigma_b^2)}{\\psi N(\\mu_a, \\sigma_a^2) + (1-\\psi) N(\\mu_b, \\sigma_b^2)}$$\n",
    "\n",
    "(recall that we are encoding `a=0` and `b=1`)\n",
    "\n",
    "This can be implemented easily in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm\n",
    "\n",
    "def Estep(x, mu, sigma, psi):\n",
    "    a = psi * norm.pdf(x, mu[0], sigma[0])\n",
    "    b = (1. - psi) * norm.pdf(x, mu[1], sigma[1])\n",
    "    return b / (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83023841958766409"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Estep(4, mu_true, sigma_true, psi_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10a565990>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nchGREvf/AcNt13F7d1h2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108998310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_range = np.linspace(-5,5)\n",
    "plt.plot(x_range, Estep(x_range, mu_true, sigma_true, psi_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **M-step** we need to maximize\n",
    "\n",
    "$$\\begin{aligned}\\text{argmax}_{\\mu,\\Sigma, \\psi}  \\sum_i \\sum_{z_i}  Q_i(z_i) \\log \\left[ \\frac{P(x_i, z_i \\,|\\, \\theta)}{Q_i(z_i)} \\right] \\\\\n",
    "= \\sum_i \\sum_{z_i} w_{ij} \\log \\left[\\frac{1}{\\sqrt{2 \\pi} \\, |\\Sigma_j|^{1/2} \\, w_{ij}} e^{-\\frac{1}{2} (x_i - \\mu_j) \\Sigma^{-1} (x_i - \\mu_j))} \\psi_j\\right]\n",
    "\\end{aligned}$$\n",
    "\n",
    "which we can show is\n",
    "\n",
    "$$\\begin{aligned}\\psi_j &= \\frac{1}{m} \\sum_i w_{ij} \\\\\n",
    "\\mu_j &= \\frac{\\sum_i w_{ij} x_i}{\\sum_i w_{ij}} \\\\\n",
    "\\sigma_j &= \\frac{\\sum_i w_{ij}(x_i - \\mu_j)^2}{\\sum_i w_{ij}}\n",
    "\\end{aligned}$$\n",
    "\n",
    "This can be coded into Python as `Mstep`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Mstep(x, w):\n",
    "    psi = np.mean(w) \n",
    "    \n",
    "    mu = [np.sum((1-w) * x)/np.sum(1-w), np.sum(w * x)/np.sum(w)]\n",
    "    \n",
    "    sigma = [np.sqrt(np.sum((1-w) * (x - mu[0])**2)/np.sum(1-w)), \n",
    "             np.sqrt(np.sum(w * (x - mu[1])**2)/np.sum(w))]\n",
    "    \n",
    "    return mu, sigma, psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: N(2.1789, 0.7876)\n",
      "B: N(4.2046, 2.5749)\n",
      "psi: 0.4720\n"
     ]
    }
   ],
   "source": [
    "# Initialize values\n",
    "mu = np.random.normal(size=2)\n",
    "sigma = np.random.uniform(0, 10, 2)\n",
    "psi = np.random.random()\n",
    "\n",
    "# Stopping criterion\n",
    "crit = 1e-4\n",
    "\n",
    "# Convergence flag\n",
    "converged = False\n",
    "\n",
    "# Loop until converged\n",
    "while not converged:\n",
    "    \n",
    "    # E-step\n",
    "    w = Estep(x, mu, sigma, psi)\n",
    "    # M-step\n",
    "    mu_new, sigma_new, psi_new = Mstep(x, w)\n",
    "    \n",
    "    # Check convergence\n",
    "    converged = ((np.abs(psi_new - psi) < crit) \n",
    "                 & np.all(np.abs((np.array(mu_new) - np.array(mu)) < crit))\n",
    "                 & np.all(np.abs((np.array(sigma_new) - np.array(sigma)) < crit)))\n",
    "    mu, sigma, psi = mu_new, sigma_new, psi_new\n",
    "                \n",
    "print('A: N({0:.4f}, {1:.4f})\\nB: N({2:.4f}, {3:.4f})\\npsi: {4:.4f}'.format(\n",
    "                        mu_new[0], sigma_new[0], mu_new[1], sigma_new[1], psi_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Zero-inflated data\n",
    "\n",
    "Code the EM algorithm to estimate the paramters of a zero-inflated Poisson (ZIP) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 75.,   0.,   7.,   0.,  10.,   0.,   5.,   0.,   3.]),\n",
       " array([ 0.        ,  0.44444444,  0.88888889,  1.33333333,  1.77777778,\n",
       "         2.22222222,  2.66666667,  3.11111111,  3.55555556,  4.        ]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10593c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# True parameter values\n",
    "mu_true = 1.5\n",
    "psi_true = .4\n",
    "n = 100\n",
    "\n",
    "# Simulate some data\n",
    "data = np.array([np.random.poisson(mu_true)*(np.random.random()<psi_true) for i in range(n)])\n",
    "plt.hist(data, bins=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import poisson\n",
    "\n",
    "def Estep(x, mu, psi):\n",
    "    a = (1-psi)*(x==0)\n",
    "    b = psi * poisson.pmf(x, mu)\n",
    "    return b / (a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Mstep(x, w):\n",
    "    psi = np.mean(w) \n",
    "    \n",
    "    mu = [np.sum(w * x)/np.sum(w)]\n",
    "    \n",
    "    return mu, psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d172fde6315c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# E-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# M-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmu_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize values\n",
    "import numpy as np\n",
    "mu = np.random.normal(size=2)\n",
    "sigma = np.random.uniform(0, 10, 2)\n",
    "psi = np.random.random()\n",
    "\n",
    "# Stopping criterion\n",
    "crit = 1e-4\n",
    "\n",
    "# Convergence flag\n",
    "converged = False\n",
    "\n",
    "# Loop until converged\n",
    "while not converged:\n",
    "    \n",
    "    # E-step\n",
    "    w = Estep(x, mu, psi)\n",
    "    # M-step\n",
    "    mu_new, psi_new = Mstep(x, w)\n",
    "    \n",
    "    # Check convergence\n",
    "    converged = ((np.abs(psi_new - psi) < crit) \n",
    "                 & np.all(np.abs((np.array(mu_new) - np.array(mu)) < crit))\n",
    "                 & np.all(np.abs((np.array(sigma_new) - np.array(sigma)) < crit)))\n",
    "    \n",
    "    import pdb; pdb.set_trace()\n",
    "    mu,psi = mu_new, psi_new\n",
    "                \n",
    "print('A: N({0:.4f}, {1:.4f})\\nB: N({2:.4f}, {3:.4f})\\npsi: {4:.4f}'.format(\n",
    "                        mu_new[0], sigma_new[0], mu_new[1], sigma_new[1], psi_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "The EM algorithm guaranteees that $P(x \\,|\\, \\theta^{(i+1)}) \\ge  P(x \\,|\\,  \\theta^{(i)})$, however there is no guarantee that we will obtain the true MLE (due to multimodality).\n",
    "\n",
    "Convergence of the EM algorithm can be slow, and it works best for likelihoods of the [exponential family of distributions](https://en.wikipedia.org/wiki/Exponential_family).\n",
    "\n",
    "In a Bayesian context, EM can also be used to obtain a maximum a posteriori (MAP) estimate for $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "[Python for Signal Processing](http://python-for-signal-processing.blogspot.com/2012/11/expectation-maximization-expectation.html)\n",
    "\n",
    "[Stanford University's Machine Learning (Coursera)](https://www.coursera.org/course/ml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
